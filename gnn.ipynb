{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4858daf1",
   "metadata": {},
   "source": [
    "# TensorFlow GNN  药物心脏毒性检测\n",
    "Introduction to TensorFlow GNN: a Graph Attention baseline for drug cardiotoxicity detection  \n",
    "![](gnn1.webp)\n",
    "\n",
    "图表显然是一个非常通用和强大的概念，可以用来表示许多不同类型的数据。例如：\n",
    "1. 社交网络可以被认为是一个图表，其中节点对应于不同的用户，边缘对应于他们的关系（即“友谊”、“追随者”等）。  \n",
    "2. 一个国家可以表示为图表，其中城市被认为是节点，连接它们的道路扮演边缘的角色。\n",
    "\n",
    "图形神经网络（GNN）是我们能够将神经网络应用于图形结构数据以学习对其进行预测的一种方式。它们的架构通常涉及堆叠消息传递层，每个层都会更新每个节点的功能i在图表中，通过将一些函数应用于其邻居的特征，\n",
    "<img src=\"gnn2.webp\" width=\"400\"/>\n",
    "GNN 应用的一个典型例子是图分类问题，我们的任务是在一组有限的可能选项中预测给定图的类别。 在监督设置中，我们有一组标记图，可以从中学习参数 {θV,θE} 通过最小化我们的预测的分类交叉熵损失来优化 GNN。 这些是在对所有节点应用最终聚合或池化操作后从 GNN 获得的，这又应该是无序的，以保留输出在节点重新标记下不变的重要属性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e361001",
   "metadata": {},
   "source": [
    "## 依赖库的安装和导入\n",
    "\n",
    "由于 TF-GNN 目前处于早期 alpha 发布阶段，因此在 Kaggle 笔记本环境中安装会出现一些问题。我发现以下组合效果很好："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f77167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# install non-Python dependencies\n",
    "!apt-get -y install graphviz graphviz-dev\n",
    "\n",
    "# Upgrade to TensorFlow 2.8\n",
    "!pip install tensorflow==2.8 tensorflow-io==0.25.0 tfds-nightly pygraphviz\n",
    "\n",
    "# Install TensorFlow-GNN\n",
    "!pip install tensorflow_gnn==0.2.0\n",
    "\n",
    "# Fix some dependencies\n",
    "!pip install httplib2==0.20.4\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cc80b6",
   "metadata": {},
   "source": [
    "现在我们已经拥有了继续操作所需的一切"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40e6f390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heng/anaconda3/envs/tf/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow v2.8.0 and TensorFlow-GNN v0.2.0\n",
      "GPUs available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# import pygraphviz as pgv\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import tensorflow_gnn as tfgnn\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow_gnn import runner\n",
    "from tensorflow_gnn.models import gat_v2\n",
    "\n",
    "print(f'Using TensorFlow v{tf.__version__} and TensorFlow-GNN v{tfgnn.__version__}')\n",
    "print(f'GPUs available: {tf.config.list_physical_devices(\"GPU\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6c85ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d775db46",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5f22af",
   "metadata": {},
   "source": [
    "Unlike other types of data, there is no standard encoding for graphs. Indeed, depending on the intended application the graph structure can be represented by:\n",
    "\n",
    "1. An adjacency matrix  Aij specifying whether the edge  i→j is present or not in  E .  \n",
    "1. An adjacency list  Ni for each node  i∈V , specifying all the nodes  j∈V for which an edge  (i,j)∈E  \n",
    "1. A list of edges  (i,j)∈E\n",
    "\n",
    "为了解决这个问题，TF-GNN 引入了 GraphTensor 对象，它封装了图结构以及节点、边和图本身的特征。 这些对象遵循图形模式，该模式指定节点和边的类型以及图形中应出现的所有功能。 因此，任何 TF-GNN 训练流程的第一步都应该是将输入数据从给定的格式转换为 GraphTensor 格式。 然后，这些 GraphTensor 对象可以像 tf.Tensor 一样被我们的 TF-GNN 模型批量处理和使用，从而极大地简化了我们的工作过程。\n",
    "\n",
    "本节的目标是执行上述任务，为我们的数据生成 DatasetProvider 对象（有关 DatasetProvider 协议的说明，请参阅此处和下一节）。 然后让我们看一下 CardioTox 数据集，我们可以从 TensorFlow 数据集 (TF-DS) 自动下载该数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4204ad64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug Cardiotoxicity dataset [1-2] is a molecule classification task to detect\n",
      "cardiotoxicity caused by binding hERG target, a protein associated with heart\n",
      "beat rhythm. The data covers over 9000 molecules with hERG activity.\n",
      "\n",
      "Note:\n",
      "\n",
      "1. The data is split into four splits: train, test-iid, test-ood1, test-ood2.\n",
      "\n",
      "2. Each molecule in the dataset has 2D graph annotations which is designed to\n",
      "facilitate graph neural network modeling. Nodes are the atoms of the molecule\n",
      "and edges are the bonds. Each atom is represented as a vector encoding basic\n",
      "atom information such as atom type. Similar logic applies to bonds.\n",
      "\n",
      "3. We include Tanimoto fingerprint distance (to training data) for each molecule\n",
      "in the test sets to facilitate research on distributional shift in graph domain.\n",
      "\n",
      "For each example, the features include:\n",
      "  atoms: a 2D tensor with shape (60, 27) storing node features. Molecules with\n",
      "    less than 60 atoms are padded with zeros. Each atom has 27 atom features.\n",
      "  pairs: a 3D tensor with shape (60, 60, 12) storing edge features. Each edge\n",
      "    has 12 edge features.\n",
      "  atom_mask: a 1D tensor with shape (60, ) storing node masks. 1 indicates the\n",
      "    corresponding atom is real, othewise a padded one.\n",
      "  pair_mask: a 2D tensor with shape (60, 60) storing edge masks. 1 indicates the\n",
      "    corresponding edge is real, othewise a padded one.\n",
      "  active: a one-hot vector indicating if the molecule is toxic or not. [0, 1]\n",
      "    indicates it's toxic, otherwise [1, 0] non-toxic.\n",
      "\n",
      "\n",
      "## References\n",
      "[1]: V. B. Siramshetty et al. Critical Assessment of Artificial Intelligence\n",
      "Methods for Prediction of hERG Channel Inhibition in the Big Data Era.\n",
      "    JCIM, 2020. https://pubs.acs.org/doi/10.1021/acs.jcim.0c00884\n",
      "\n",
      "[2]: K. Han et al. Reliable Graph Neural Networks for Drug Discovery Under\n",
      "Distributional Shift.\n",
      "    NeurIPS DistShift Workshop 2021. https://arxiv.org/abs/2111.12951\n"
     ]
    }
   ],
   "source": [
    "dataset_splits, dataset_info = tfds.load('cardiotox', data_dir='data/tfds', with_info=True)\n",
    "\n",
    "\n",
    "print(dataset_info.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4707c741",
   "metadata": {},
   "source": [
    "如前所述，我们只有一组节点（我们称之为“原子”）和一组边（我们称之为“键”）。 当然，所有边的两个端点都有“原子”型节点。 节点和边都有一个特征向量，前者是 27 维“atom_features”向量，后者是 12 维“bond_features”向量。 此外，图本身具有给出其上下文的全局特征，在本例中是毒性类别“毒性”，这实际上是我们想要预测的标签，以及我们通常会忽略的分子 ID“分子 ID”。\n",
    "\n",
    "上述所有内容都可以编码在以下图形模式中，指定图形的结构和内容："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08f4a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_schema_pbtxt = \"\"\"\n",
    "node_sets {\n",
    "  key: \"atom\"\n",
    "  value {\n",
    "    description: \"An atom in the molecule.\"\n",
    "\n",
    "    features {\n",
    "      key: \"atom_features\"\n",
    "      value: {\n",
    "        description: \"[DATA] The features of the atom.\"\n",
    "        dtype: DT_FLOAT\n",
    "        shape { dim { size: 27 } }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "edge_sets {\n",
    "  key: \"bond\"\n",
    "  value {\n",
    "    description: \"A bond between two atoms in the molecule.\"\n",
    "    source: \"atom\"\n",
    "    target: \"atom\"\n",
    "\n",
    "    features {\n",
    "      key: \"bond_features\"\n",
    "      value: {\n",
    "        description: \"[DATA] The features of the bond.\"\n",
    "        dtype: DT_FLOAT\n",
    "        shape { dim { size: 12 } }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "context {\n",
    "  features {\n",
    "    key: \"toxicity\"\n",
    "    value: {\n",
    "      description: \"[LABEL] The toxicity class of the molecule (0 -> non-toxic; 1 -> toxic).\"\n",
    "      dtype: DT_INT64\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  features {\n",
    "    key: \"molecule_id\"\n",
    "    value: {\n",
    "      description: \"[LABEL] The id of the molecule.\"\n",
    "      dtype: DT_STRING\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dec415",
   "metadata": {},
   "source": [
    "这个 schema 是一个文本 protobuf，我们可以解析它以获得 GraphTensorSpec（想想 GraphTensor 对象的 TensorSpec）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba533208",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_schema = tfgnn.parse_schema(graph_schema_pbtxt)\n",
    "graph_spec = tfgnn.create_graph_spec_from_schema_pb(graph_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b400c7d9",
   "metadata": {},
   "source": [
    "然后，我们应该将输入数据集转换为符合 graph_spec 的 GraphTensor 对象，我们将使用以下辅助函数来完成此操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82488646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph_tensor(datapoint):\n",
    "    \"\"\"\n",
    "    Convert a datapoint from the TF-DS CardioTox dataset into a `GraphTensor`.\n",
    "    \"\"\"\n",
    "    # atom_mask is non-zero only for real atoms\n",
    "    # [ V, ]\n",
    "    atom_indices = tf.squeeze(tf.where(datapoint['atom_mask']), axis=1)\n",
    "    \n",
    "    # only keep features of real atoms\n",
    "    # [ V, 27 ]\n",
    "    atom_features = tf.gather(datapoint['atoms'], atom_indices)\n",
    "    \n",
    "    # restrict the bond mask to real atoms\n",
    "    # [ V, V ]\n",
    "    pair_mask = tf.gather(tf.gather(datapoint['pair_mask'], atom_indices, axis=0), atom_indices, axis=1)\n",
    "    \n",
    "    # restrict the bond features to real atoms\n",
    "    # [ V, V, 12 ]\n",
    "    pairs = tf.gather(tf.gather(datapoint['pairs'], atom_indices, axis=0), atom_indices, axis=1)\n",
    "    \n",
    "    # pair_mask is non-zero only for real bonds\n",
    "    # [ E, 2 ]\n",
    "    bond_indices = tf.where(pair_mask)\n",
    "    \n",
    "    # only keep features of real bonds\n",
    "    # [ E, 12 ]\n",
    "    bond_features = tf.gather_nd(pairs, bond_indices)\n",
    "    \n",
    "    # separate sources and targets for each bond\n",
    "    # [ E, ]\n",
    "    sources, targets = tf.unstack(tf.transpose(bond_indices))\n",
    "\n",
    "    # active is [1, 0] for non-toxic molecules, [0, 1] for toxic molecules\n",
    "    # [ ]\n",
    "    toxicity = tf.argmax(datapoint['active'])\n",
    "    \n",
    "    # the molecule_id is included for reference\n",
    "    # [ ]\n",
    "    molecule_id = datapoint['molecule_id']\n",
    "\n",
    "    # create a GraphTensor from all of the above\n",
    "    atom = tfgnn.NodeSet.from_fields(features={'atom_features': atom_features},\n",
    "                                     sizes=tf.shape(atom_indices))\n",
    "    \n",
    "    atom_adjacency = tfgnn.Adjacency.from_indices(source=('atom', tf.cast(sources, dtype=tf.int32)),\n",
    "                                                  target=('atom', tf.cast(targets, dtype=tf.int32)))\n",
    "    \n",
    "    bond = tfgnn.EdgeSet.from_fields(features={'bond_features': bond_features},\n",
    "                                     sizes=tf.shape(sources),\n",
    "                                     adjacency=atom_adjacency)\n",
    "    \n",
    "    context = tfgnn.Context.from_fields(features={'toxicity': [toxicity], 'molecule_id': [molecule_id]})\n",
    "    \n",
    "    return tfgnn.GraphTensor.from_pieces(node_sets={'atom': atom}, edge_sets={'bond': bond}, context=context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76322f76",
   "metadata": {},
   "source": [
    "我们现在可以将此函数映射到数据集上，让它们流式传输 GraphTensor 对象："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a23ee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset_splits['train'].map(make_graph_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c85b517e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphTensor(\n",
       "  context=Context(features={'toxicity': <tf.Tensor: shape=(1,), dtype=tf.int64>, 'molecule_id': <tf.Tensor: shape=(1,), dtype=tf.string>}, sizes=[1], shape=(), indices_dtype=tf.int32),\n",
       "  node_set_names=['atom'],\n",
       "  edge_set_names=['bond'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor = next(iter(train_dataset))\n",
    "graph_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a75d5ea",
   "metadata": {},
   "source": [
    "并检查由此产生的 GraphTensor 是否与我们之前定义的 GraphTensorSpec 兼容："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "251d3111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_spec.is_compatible_with(graph_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396a1dc0",
   "metadata": {},
   "source": [
    "但是，为了避免多次处理数据（这会减慢所有输入管道的速度），首先将所有数据转储到 TFRecord 文件中会很方便。 稍后我们可以轻松加载这些数据集，而不是我们映射 make_graph_tensor 函数的原始 TF-DS 数据集。\n",
    "\n",
    "注意：下面的 create_tfrecords 方法运行良好，相当通用，可以立即重用于其他小型应用程序。 然而，对于大规模数据集，使用 tf.data.Dataset.cache 或 tf.data.Dataset.snapshot 的替代方法会更好，因为它们将允许更多优化，例如 分片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "110e1f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfrecords(dataset_splits, dataset_info):\n",
    "    \"\"\"\n",
    "    Dump all splits of the given dataset to TFRecord files.\n",
    "    \"\"\"\n",
    "    for split_name, dataset in dataset_splits.items():\n",
    "        filename = f'data/{dataset_info.name}-{split_name}.tfrecord'\n",
    "        print(f'creating {filename}...')\n",
    "        \n",
    "        # convert all datapoints to GraphTensor\n",
    "        dataset = dataset.map(make_graph_tensor, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        \n",
    "        # serialize to TFRecord files\n",
    "        with tf.io.TFRecordWriter(filename) as writer:\n",
    "            for graph_tensor in tqdm(iter(dataset), total=dataset_info.splits[split_name].num_examples):\n",
    "                example = tfgnn.write_example(graph_tensor)\n",
    "                writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91dc10ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating data/cardiotox-train.tfrecord...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6523/6523 [00:27<00:00, 238.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating data/cardiotox-validation.tfrecord...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1631/1631 [00:06<00:00, 240.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating data/cardiotox-test.tfrecord...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 839/839 [00:03<00:00, 248.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating data/cardiotox-test2.tfrecord...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 177/177 [00:00<00:00, 233.50it/s]\n"
     ]
    }
   ],
   "source": [
    "create_tfrecords(dataset_splits, dataset_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a53e5a4",
   "metadata": {},
   "source": [
    "最后，我们可以使用 TFRecordDatasetProvider 类创建符合 DatasetProvider 的对象，该对象读取这些 TFRecord 文件并通过其 get_dataset 方法提供 tf.data.Dataset 对象供我们使用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf9de53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_provider = runner.TFRecordDatasetProvider(file_pattern='data/cardiotox-train.tfrecord')\n",
    "valid_dataset_provider = runner.TFRecordDatasetProvider(file_pattern='data/cardiotox-validation.tfrecord')\n",
    "test1_dataset_provider = runner.TFRecordDatasetProvider(file_pattern='data/cardiotox-test.tfrecord')\n",
    "test2_dataset_provider = runner.TFRecordDatasetProvider(file_pattern='data/cardiotox-test2.tfrecord')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f81efd9",
   "metadata": {},
   "source": [
    "## DatasetProvider 协议\n",
    "\n",
    "上面定义的每个 DatasetProvider 通常都会生成一个序列化 GraphTensor 对象的数据集，我们需要在检查之前对其进行解析。 这里提到这一点仅供参考：编排器将在实际训练过程中透明地处理这一点。\n",
    "\n",
    "为了获取数据集，我们需要提供输入上下文："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4d2a63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset_provider.get_dataset(context=tf.distribute.InputContext())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d2b8c9",
   "metadata": {},
   "source": [
    "然后，我们将 tfgnn.parse_single_example 映射到该数据集，为我们的图指定适当的 GraphTensorSpec："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "033f5632",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(lambda serialized: tfgnn.parse_single_example(serialized=serialized, spec=graph_spec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050cce23",
   "metadata": {},
   "source": [
    "然后我们可以像以前一样流式传输 GraphTensor 对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8acf7c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphTensor(\n",
       "  context=Context(features={'molecule_id': <tf.Tensor: shape=(1,), dtype=tf.string>, 'toxicity': <tf.Tensor: shape=(1,), dtype=tf.int64>}, sizes=[1], shape=(), indices_dtype=tf.int32),\n",
       "  node_set_names=['atom'],\n",
       "  edge_set_names=['bond'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor = next(iter(train_dataset))\n",
    "graph_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a89c574",
   "metadata": {},
   "source": [
    "## 数据核查\n",
    "\n",
    "节点和边特征并不是特别说明性的，但是如果需要的话我们仍然可以直接访问它们。 首先，请注意该特定分子具有以下数字 V=|V| 原子数：  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26e63e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int32, numpy=array([33], dtype=int32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor.node_sets['atom'].sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d55f63",
   "metadata": {},
   "source": [
    "它们的特征被收集在形状 (V, 27) 的张量中，我们可以像这样访问它："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe0f0fe",
   "metadata": {},
   "source": [
    "类似地，数字E=|E| 分子中的键为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "614c3b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(33, 27), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 2., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 2., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor.node_sets['atom']['atom_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "764a1bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int32, numpy=array([68], dtype=int32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor.edge_sets['bond'].sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f7c752",
   "metadata": {},
   "source": [
    "它们的特征被收集在形状为 (E, 12) 的张量中，我们可以像这样访问它："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1a1c291",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(68, 12), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor.edge_sets['bond']['bond_features']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0863ce7f",
   "metadata": {},
   "source": [
    "然后，边缘端点的 id 存储在几个形状为 (E,) 的张量中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a279b2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(68,), dtype=int32, numpy=\n",
       "array([ 0,  1,  1,  1,  2,  2,  2,  3,  3,  4,  4,  5,  5,  5,  6,  7,  7,\n",
       "        8,  8,  9,  9, 10, 10, 10, 11, 12, 12, 13, 13, 14, 14, 15, 15, 15,\n",
       "       16, 17, 17, 18, 18, 19, 19, 20, 20, 20, 21, 22, 23, 23, 23, 24, 25,\n",
       "       25, 25, 26, 26, 27, 27, 28, 28, 29, 29, 30, 30, 30, 31, 31, 31, 32],\n",
       "      dtype=int32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor.edge_sets['bond'].adjacency.source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68979115",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(68,), dtype=int32, numpy=\n",
       "array([ 1,  0,  2, 31,  1,  3, 23,  2,  4,  3,  5,  4,  6,  7,  5,  5,  8,\n",
       "        7,  9,  8, 10,  9, 11, 12, 10, 10, 13, 12, 14, 13, 15, 14, 16, 17,\n",
       "       15, 15, 18, 17, 19, 18, 20, 19, 21, 22, 20, 20,  2, 24, 25, 23, 23,\n",
       "       26, 30, 25, 27, 26, 28, 27, 29, 28, 30, 25, 29, 31,  1, 30, 32, 31],\n",
       "      dtype=int32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor.edge_sets['bond'].adjacency.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704bf00a",
   "metadata": {},
   "source": [
    "最后，有关图的全局信息由其上下文提供"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2129358b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor.context['toxicity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a160fe0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=string, numpy=\n",
       "array([b'CC1=C(C/C=C(\\\\C)CCC[C@H](C)CCC[C@H](C)CCCC(C)C)C(=O)c2ccccc2C1=O'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor.context['molecule_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef78e45",
   "metadata": {},
   "source": [
    "有了所有这些，我们可以编写以下辅助函数来可视化图表："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b7c8507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_molecule(graph_tensor):\n",
    "    \"\"\"\n",
    "    Plot the `GraphTensor` representation of a molecule.\n",
    "    \"\"\"\n",
    "    (molecule_id,) = graph_tensor.context['molecule_id'].numpy()\n",
    "    (toxicity,) = graph_tensor.context['toxicity'].numpy()\n",
    "\n",
    "    sources = graph_tensor.edge_sets['bond'].adjacency.source.numpy()\n",
    "    targets = graph_tensor.edge_sets['bond'].adjacency.target.numpy()\n",
    "\n",
    "    pgvGraph = pgv.AGraph()\n",
    "    pgvGraph.graph_attr['label'] = f'toxicity = {toxicity}\\n\\nmolecule_id = {molecule_id.decode()}'\n",
    "\n",
    "    for edge in zip(sources, targets):\n",
    "        pgvGraph.add_edge(edge)\n",
    "\n",
    "    return Image(pgvGraph.draw(format='png', prog='dot'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31713475",
   "metadata": {},
   "source": [
    "<img src=\"gnn.png\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d47fe1",
   "metadata": {},
   "source": [
    "## GraphTensor 批量化\n",
    "\n",
    "GraphTensor 数据集可以像往常一样进行批处理，从而产生产生更高等级 GraphTensor 对象的新数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "944fdb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "batched_train_dataset = train_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78595afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor_batch = next(iter(batched_train_dataset))\n",
    "graph_tensor_batch.rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fede4b8",
   "metadata": {},
   "source": [
    "生成的 GraphTensor 现在包含 tf.RaggedTensor 形式的特征，因为不同的图可以具有不同数量的节点和边："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "442b5130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, None, 27])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor_batch.node_sets['atom']['atom_features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c5aadbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, None, 12])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor_batch.edge_sets['bond']['bond_features'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db011ee0",
   "metadata": {},
   "source": [
    "其中形状现在对应于 (batch_size, V, 27) 和 (batch_size, E, 12)。\n",
    "\n",
    "然而，TF-GNN 中的所有层都期望标量图作为其输入，因此在实际使用一批图之前，我们应该始终将批次中的不同图“合并”为具有多个断开连接的组件的单个图（其中 TF-GNN 自动 跟踪）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8f096bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar_graph_tensor = graph_tensor_batch.merge_batch_to_components()\n",
    "scalar_graph_tensor.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89c396c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1562, 27])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar_graph_tensor.node_sets['atom']['atom_features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8c4c4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3370, 12])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar_graph_tensor.edge_sets['bond']['bond_features'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6281bcd",
   "metadata": {},
   "source": [
    "然而，我们应该注意到，编排器将再次透明地为我们处理批处理和合并组件，因此只要我们不自定义训练例程，我们就不必担心这一点。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b1461a",
   "metadata": {},
   "source": [
    "## 简单的MPNN模型\n",
    "\n",
    "GNN 的常见架构由一个初始层组成，该初始层对图特征进行预处理，通常为节点和/或边生成隐藏状态，后面是一层或多层消息传递工作，如简介中所述。 本节的目标是定义一个 vanilla_mpnn_model 函数，可用于从以下位置创建此类简单的 GNN：\n",
    "\n",
    "1. 执行预处理的初始层\n",
    "1. 一个层堆叠多个消息传递层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfefeefe",
   "metadata": {},
   "source": [
    "## 初始化图\n",
    "\n",
    "对于第一个任务，我们将使用 tfgnn.keras.layers.MapFeatures 层通过密集层传递原子和键的各自特征，为原子和键创建隐藏状态向量。 由此产生的隐藏状态将具有维度hidden_size，对应于dV和dE简介的符号\n",
    "  。\n",
    "\n",
    "以下辅助函数将为给定的超参数创建一个初始 MapFeatures 图层：\n",
    "\n",
    "1. hidden_size：隐藏尺寸 dV 和 dE\n",
    "1.  \n",
    "激活：密集层的激活"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41eb947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_map_features(hidden_size, activation='relu'):\n",
    "    \"\"\"\n",
    "    Initial pre-processing layer for a GNN (use as a class constructor).\n",
    "    \"\"\"\n",
    "    def node_sets_fn(node_set, node_set_name):\n",
    "        if node_set_name == 'atom':\n",
    "            return tf.keras.layers.Dense(units=hidden_size, activation=activation)(node_set['atom_features'])\n",
    "    \n",
    "    def edge_sets_fn(edge_set, edge_set_name):\n",
    "        if edge_set_name == 'bond':\n",
    "            return tf.keras.layers.Dense(units=hidden_size, activation=activation)(edge_set['bond_features'])\n",
    "    \n",
    "    return tfgnn.keras.layers.MapFeatures(node_sets_fn=node_sets_fn,\n",
    "                                          edge_sets_fn=edge_sets_fn,\n",
    "                                          name='graph_embedding')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5f8f93",
   "metadata": {},
   "source": [
    "我们可以检查结果层是否用指定维度的隐藏状态替换了“atom_features”和“bond_features”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c5a98a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_embedding = get_initial_map_features(hidden_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "262ab597",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_graph = graph_embedding(scalar_graph_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a929188f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_state': <tf.Tensor: shape=(1562, 128), dtype=float32, numpy=\n",
       "array([[0.        , 0.2920603 , 0.16877857, ..., 0.02003821, 0.00672814,\n",
       "        0.04361148],\n",
       "       [0.        , 0.        , 0.02534644, ..., 0.04332802, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.02534644, ..., 0.04332802, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.32096922, 0.20735013, ..., 0.        , 0.09112668,\n",
       "        0.14522932],\n",
       "       [0.        , 0.14401045, 0.        , ..., 0.19082573, 0.        ,\n",
       "        0.19302632],\n",
       "       [0.        , 0.        , 0.        , ..., 0.1429371 , 0.        ,\n",
       "        0.22474754]], dtype=float32)>}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_graph.node_sets['atom'].features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5d54da",
   "metadata": {},
   "source": [
    "请注意，原子和键特征现在都命名为“hidden_​​state”；我们当然可以选择不同的名称，但保留默认的 tfgnn.HIDDEN_STATE 将使我们不必在后面指定功能名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b2e044f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_state': <tf.Tensor: shape=(3370, 128), dtype=float32, numpy=\n",
       "array([[0.0056771 , 0.07958694, 0.        , ..., 0.21486597, 0.41878182,\n",
       "        0.2994969 ],\n",
       "       [0.0056771 , 0.07958694, 0.        , ..., 0.21486597, 0.41878182,\n",
       "        0.2994969 ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.12333959, 0.16223049,\n",
       "        0.2355265 ],\n",
       "       ...,\n",
       "       [0.17426147, 0.        , 0.        , ..., 0.137586  , 0.36240458,\n",
       "        0.40004316],\n",
       "       [0.17426147, 0.        , 0.        , ..., 0.137586  , 0.36240458,\n",
       "        0.40004316],\n",
       "       [0.17426147, 0.        , 0.        , ..., 0.137586  , 0.36240458,\n",
       "        0.40004316]], dtype=float32)>}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_graph.edge_sets['bond'].features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef3b947",
   "metadata": {},
   "source": [
    "## 消息传递层的堆叠\n",
    "\n",
    "为了说明如何构建消息传递层堆栈，我们将使用 models.gat_v2 模块中提供的预构建图注意力 (GAT) [2] 层。 然后，我们定义一个消息传递神经网络（MPNN）层，连续应用这些具有超参数的层：\n",
    "\n",
    "1. hidden_size：隐藏尺寸 dV 和 dE\n",
    " \n",
    "1. hops：堆栈的层数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f8c0aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPNN(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    A basic stack of message-passing Graph Attention layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, hops, name='gat_mpnn', **kwargs):\n",
    "        self.hidden_size = hidden_size\n",
    "        self.hops = hops\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        \n",
    "        self.mp_layers = [self._mp_factory(name=f'message_passing_{i}') for i in range(hops)]\n",
    "    \n",
    "    def _mp_factory(self, name):\n",
    "        return gat_v2.GATv2GraphUpdate(num_heads=1,\n",
    "                                       per_head_channels=self.hidden_size,\n",
    "                                       edge_set_name='bond',\n",
    "                                       sender_edge_feature=tfgnn.HIDDEN_STATE,\n",
    "                                       name=name)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'hidden_size': self.hidden_size,\n",
    "            'hops': self.hops\n",
    "        })\n",
    "        return config\n",
    "        \n",
    "    def call(self, graph_tensor):\n",
    "        for layer in self.mp_layers:\n",
    "            graph_tensor = layer(graph_tensor)\n",
    "        return graph_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78860a77",
   "metadata": {},
   "source": [
    "我们现在可以检查该层是否处理来自初始特征图的嵌入图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7bf6b43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpnn = MPNN(hidden_size=128, hops=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d0266971",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_graph = mpnn(embedded_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca3df2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_state': <tf.Tensor: shape=(1562, 128), dtype=float32, numpy=\n",
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.00236014, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.00310817, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]], dtype=float32)>}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_graph.node_sets['atom'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "29238df2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_state': <tf.Tensor: shape=(3370, 128), dtype=float32, numpy=\n",
       "array([[0.0056771 , 0.07958694, 0.        , ..., 0.21486597, 0.41878182,\n",
       "        0.2994969 ],\n",
       "       [0.0056771 , 0.07958694, 0.        , ..., 0.21486597, 0.41878182,\n",
       "        0.2994969 ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.12333959, 0.16223049,\n",
       "        0.2355265 ],\n",
       "       ...,\n",
       "       [0.17426147, 0.        , 0.        , ..., 0.137586  , 0.36240458,\n",
       "        0.40004316],\n",
       "       [0.17426147, 0.        , 0.        , ..., 0.137586  , 0.36240458,\n",
       "        0.40004316],\n",
       "       [0.17426147, 0.        , 0.        , ..., 0.137586  , 0.36240458,\n",
       "        0.40004316]], dtype=float32)>}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_graph.edge_sets['bond'].features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebeccdf",
   "metadata": {},
   "source": [
    "## 组建模型\n",
    "\n",
    "我们现在准备将这两种成分组合到 tf.keras.Model 中，该模型采用代表分子的 GraphTensor 作为输入，并生成另一个具有所有原子隐藏状态的 GraphTensor 作为输出。 我们使用 Keras 的功能 API 定义一个 vanilla_mpnn_model 辅助函数，返回所需的 tf.keras.Model："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c6314f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanilla_mpnn_model(graph_tensor_spec, init_states_fn, pass_messages_fn):\n",
    "    \"\"\"\n",
    "    Chain an initialization layer and a message-passing stack to produce a `tf.keras.Model`.\n",
    "    \"\"\"\n",
    "    graph_tensor = tf.keras.layers.Input(type_spec=graph_tensor_spec)\n",
    "    embedded_graph = init_states_fn(graph_tensor)\n",
    "    hidden_graph = pass_messages_fn(embedded_graph)\n",
    "    return tf.keras.Model(inputs=graph_tensor, outputs=hidden_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "653a7dfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [()]                      0         \n",
      "                                                                 \n",
      " graph_embedding (MapFeature  ()                       5248      \n",
      " s)                                                              \n",
      "                                                                 \n",
      " gat_mpnn (MPNN)             ()                        396288    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 401,536\n",
      "Trainable params: 401,536\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = vanilla_mpnn_model(graph_tensor_spec=graph_spec,\n",
    "                           init_states_fn=graph_embedding,\n",
    "                           pass_messages_fn=mpnn)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea304db1",
   "metadata": {},
   "source": [
    "为了以后方便起见，让我们将所有这些逻辑封装在一个函数中，我们可以使用它来获取固定超参数的模型构造函数。 按照惯例，返回的构造函数仅采用模型输入图的 GraphTensorSpec，并且为了更好地衡量，我们的构造函数还将添加一些 L2 通过 l2_coefficient 超参数进行正则化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c59bfeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_creation_fn(hidden_size, hops, activation='relu', l2_coefficient=1e-3):\n",
    "    \"\"\"\n",
    "    Return a model constructor for a given set of hyperparameters.\n",
    "    \"\"\"\n",
    "    def model_creation_fn(graph_tensor_spec):\n",
    "        initial_map_features = get_initial_map_features(hidden_size=hidden_size, activation=activation)\n",
    "        mpnn = MPNN(hidden_size=hidden_size, hops=hops)\n",
    "        \n",
    "        model = vanilla_mpnn_model(graph_tensor_spec=graph_tensor_spec,\n",
    "                                   init_states_fn=initial_map_features,\n",
    "                                   pass_messages_fn=mpnn)\n",
    "        model.add_loss(lambda: tf.reduce_sum([tf.keras.regularizers.l2(l2=l2_coefficient)(weight) for weight in model.trainable_weights]))\n",
    "        return model\n",
    "    return model_creation_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6cb11582",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpnn_creation_fn = get_model_creation_fn(hidden_size=128, hops=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ec06e2be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [()]                      0         \n",
      "                                                                 \n",
      " graph_embedding (MapFeature  ()                       5248      \n",
      " s)                                                              \n",
      "                                                                 \n",
      " gat_mpnn (MPNN)             ()                        396288    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 401,536\n",
      "Trainable params: 401,536\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = mpnn_creation_fn(graph_spec)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38af0e0",
   "metadata": {},
   "source": [
    "## 图二分类\n",
    "\n",
    "任务配置\n",
    "\n",
    "有了可用的 GNN 模型，我们现在准备将其应用于手头的任务，即预测其毒性的分子二元分类。 这涉及：\n",
    "\n",
    "1. 添加读出和预测头，根据 GNN 计算的特征计算每个类别的逻辑。\n",
    "1. 定义要最小化的损失函数，在本例中应该是分类交叉熵损失。\n",
    "1. 定义我们在训练和验证期间有兴趣测量的指标。  \n",
    "\n",
    "编排器定义了任务协议来实现这些目标，并方便地提供了一个符合该协议的预实现的 GraphBinaryClassification 类。 虽然我们可以按原样使用它，但出于说明目的，我们将通过两种方式扩展其基本实现：\n",
    "\n",
    "1. 我们将包括 AUROC 指标。\n",
    "1. 我们将概括读出和预测头以包括隐藏层。  \n",
    "\n",
    "首先，我们围绕 tf.keras.metrics.AUC 类定义一个简单的包装器，以使其适应我们的约定："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1ea0a15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AUROC(tf.keras.metrics.AUC):\n",
    "    \"\"\"\n",
    "    AUROC metric computation for binary classification from logits.\n",
    "    \n",
    "    y_true: true labels, with shape (batch_size,)\n",
    "    y_pred: predicted logits, with shape (batch_size, 2)\n",
    "    \"\"\"\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        super().update_state(y_true, tf.math.softmax(y_pred, axis=-1)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d3dc18",
   "metadata": {},
   "source": [
    "接下来，我们对 GraphBinaryClassification 任务进行子类化并重写其调整和度量方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4e3ba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphBinaryClassification(runner.GraphBinaryClassification):\n",
    "    \"\"\"\n",
    "    A GraphBinaryClassification task with a hidden layer in the prediction head, and additional metrics.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim, *args, **kwargs):\n",
    "        self._hidden_dim = hidden_dim\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def adapt(self, model):\n",
    "        hidden_state = tfgnn.pool_nodes_to_context(model.output,\n",
    "                                                   node_set_name=self._node_set_name,\n",
    "                                                   reduce_type=self._reduce_type,\n",
    "                                                   feature_name=self._state_name)\n",
    "        \n",
    "        hidden_state = tf.keras.layers.Dense(units=self._hidden_dim, activation='relu', name='hidden_layer')(hidden_state)\n",
    "        \n",
    "        logits = tf.keras.layers.Dense(units=self._units, name='logits')(hidden_state)\n",
    "        \n",
    "        return tf.keras.Model(inputs=model.inputs, outputs=logits)\n",
    "    \n",
    "    def metrics(self):\n",
    "        return (*super().metrics(), AUROC(name='AUROC'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6da877f",
   "metadata": {},
   "source": [
    "要创建此类的实例，我们需要指定将用于聚合隐藏状态以进行预测的节点集（请记住，在我们的例子中只有一个“原子”）和类的数量（两个，用于有毒和非 -有毒），以及新的超参数hidden_dim："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e7f62bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = GraphBinaryClassification(hidden_dim=256, node_set_name='atom', num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af026fcd",
   "metadata": {},
   "source": [
    "然后，该实例提供了我们训练所需的一切，即： 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ea913778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<keras.losses.SparseCategoricalCrossentropy at 0x7f1a1840e3a0>,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd81bc16",
   "metadata": {},
   "source": [
    "指标："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3593e83d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<keras.metrics.SparseCategoricalAccuracy at 0x7f1a1840ed00>,\n",
       " <keras.metrics.SparseCategoricalCrossentropy at 0x7f1ab00842b0>,\n",
       " <__main__.AUROC at 0x7f1a1840e040>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbedf71",
   "metadata": {},
   "source": [
    "一种将读出和预测头放置在 GNN 顶部的适应方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b2c1d686",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [()]                 0           []                               \n",
      "                                                                                                  \n",
      " graph_embedding (MapFeatures)  ()                   5248        ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " gat_mpnn (MPNN)                ()                   396288      ['graph_embedding[0][0]']        \n",
      "                                                                                                  \n",
      " input.node_sets (InstancePrope  {'atom': ()}        0           ['gat_mpnn[0][0]']               \n",
      " rty)                                                                                             \n",
      "                                                                                                  \n",
      " input.sizes (InstanceProperty)  (1,)                0           ['input.node_sets[0][0]']        \n",
      "                                                                                                  \n",
      " tf.math.cumsum (TFOpLambda)    (1,)                 0           ['input.sizes[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLambda  ()                  0           ['input.sizes[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.ones_like (TFOpLambda)      (1,)                 0           ['tf.math.cumsum[0][0]']         \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.reduce_sum[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.unsorted_segment_sum (  (None,)             0           ['tf.ones_like[0][0]',           \n",
      " TFOpLambda)                                                      'tf.__operators__.add[0][0]',   \n",
      "                                                                  'tf.math.cumsum[0][0]']         \n",
      "                                                                                                  \n",
      " tf.math.cumsum_1 (TFOpLambda)  (None,)              0           ['tf.math.unsorted_segment_sum[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " input._get_features_ref_4 (Ins  {'hidden_state': (N  0          ['input.node_sets[0][0]']        \n",
      " tanceProperty)                 one, 128)}                                                        \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None,)             0           ['tf.math.cumsum_1[0][0]',       \n",
      " ingOpLambda)                                                     'tf.math.reduce_sum[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.unsorted_segment_mean   (1, 128)            0           ['input._get_features_ref_4[0][0]\n",
      " (TFOpLambda)                                                    ',                               \n",
      "                                                                  'tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " hidden_layer (Dense)           (1, 256)             33024       ['tf.math.unsorted_segment_mean[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " logits (Dense)                 (1, 2)               514         ['hidden_layer[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 435,074\n",
      "Trainable params: 435,074\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classification_model = task.adapt(model)\n",
    "classification_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9510a180",
   "metadata": {},
   "source": [
    "然后，生成的模型会为每个类生成 logits，并将 GraphTensor 作为输入："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7b944bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-0.2722813 ,  0.09090953]], dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model(graph_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c650fd19",
   "metadata": {},
   "source": [
    "预处理器方法，可用于在到达 GNN 之前对图进行预处理，但此处仍不使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3afd8686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.preprocessors()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8e1c36",
   "metadata": {},
   "source": [
    "## 训练\n",
    "\n",
    "我们现在准备好训练模型了。首先，我们创建一个 KerasTrainer 实例，它利用 Keras 的 fit 方法实现协调器的 Trainer 协议："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c7aab9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = runner.KerasTrainer(strategy=tf.distribute.get_strategy(), model_dir='model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5986a762",
   "metadata": {},
   "source": [
    "接下来，我们定义一个符合 GraphTensorProcessorFn 协议的简单函数，该函数从 GraphTensor 对象中提取标签，以便在监督训练期间使用（该函数将映射到数据集，然后传递到 tf.keras.Model.fit 方法）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8c4b646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(graph_tensor):\n",
    "    \"\"\"\n",
    "    Extract the toxicity class label from the `GraphTensor` representation of a molecule.\n",
    "    Return a pair compatible with the `tf.keras.Model.fit` method.\n",
    "    \"\"\"\n",
    "    return graph_tensor, graph_tensor.context['toxicity']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d9da0e",
   "metadata": {},
   "source": [
    "最后，我们可以把所有东西放在一起，一边喝咖啡，一边观看一些进度条的移动:-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e1b1fc2a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heng/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_7/node_set_update_7/gat_v2_conv/Reshape_3:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_7/node_set_update_7/gat_v2_conv/Reshape_2:0\", shape=(None, 1, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_7/node_set_update_7/gat_v2_conv/Cast:0\", shape=(3,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/heng/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_7/node_set_update_7/gat_v2_conv/Reshape_6:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_7/node_set_update_7/gat_v2_conv/Reshape_5:0\", shape=(None, 1, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_7/node_set_update_7/gat_v2_conv/Cast_1:0\", shape=(3,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/heng/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_6/node_set_update_6/gat_v2_conv/Reshape_3:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_6/node_set_update_6/gat_v2_conv/Reshape_2:0\", shape=(None, 1, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_6/node_set_update_6/gat_v2_conv/Cast:0\", shape=(3,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/heng/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_6/node_set_update_6/gat_v2_conv/Reshape_6:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_6/node_set_update_6/gat_v2_conv/Reshape_5:0\", shape=(None, 1, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_6/node_set_update_6/gat_v2_conv/Cast_1:0\", shape=(3,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/heng/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_5/node_set_update_5/gat_v2_conv/Reshape_3:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_5/node_set_update_5/gat_v2_conv/Reshape_2:0\", shape=(None, 1, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_5/node_set_update_5/gat_v2_conv/Cast:0\", shape=(3,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/heng/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_5/node_set_update_5/gat_v2_conv/Reshape_6:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_5/node_set_update_5/gat_v2_conv/Reshape_5:0\", shape=(None, 1, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_5/node_set_update_5/gat_v2_conv/Cast_1:0\", shape=(3,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/heng/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_4/node_set_update_4/gat_v2_conv/Reshape_3:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_4/node_set_update_4/gat_v2_conv/Reshape_2:0\", shape=(None, 1, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_4/node_set_update_4/gat_v2_conv/Cast:0\", shape=(3,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/heng/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_4/node_set_update_4/gat_v2_conv/Reshape_6:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_4/node_set_update_4/gat_v2_conv/Reshape_5:0\", shape=(None, 1, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_4/node_set_update_4/gat_v2_conv/Cast_1:0\", shape=(3,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/heng/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_3/node_set_update_3/gat_v2_conv/Reshape_3:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_3/node_set_update_3/gat_v2_conv/Reshape_2:0\", shape=(None, 1, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_3/node_set_update_3/gat_v2_conv/Cast:0\", shape=(3,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/heng/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_3/node_set_update_3/gat_v2_conv/Reshape_6:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_3/node_set_update_3/gat_v2_conv/Reshape_5:0\", shape=(None, 1, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_3/node_set_update_3/gat_v2_conv/Cast_1:0\", shape=(3,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/heng/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_2/node_set_update_2/gat_v2_conv/Reshape_3:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_2/node_set_update_2/gat_v2_conv/Reshape_2:0\", shape=(None, 1, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_2/node_set_update_2/gat_v2_conv/Cast:0\", shape=(3,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/heng/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_2/node_set_update_2/gat_v2_conv/Reshape_6:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_2/node_set_update_2/gat_v2_conv/Reshape_5:0\", shape=(None, 1, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_2/node_set_update_2/gat_v2_conv/Cast_1:0\", shape=(3,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/heng/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_1/node_set_update_1/gat_v2_conv/Reshape_3:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_1/node_set_update_1/gat_v2_conv/Reshape_2:0\", shape=(None, 1, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_1/node_set_update_1/gat_v2_conv/Cast:0\", shape=(3,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/heng/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_1/node_set_update_1/gat_v2_conv/Reshape_6:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_1/node_set_update_1/gat_v2_conv/Reshape_5:0\", shape=(None, 1, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_1/node_set_update_1/gat_v2_conv/Cast_1:0\", shape=(3,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/heng/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_0/node_set_update/gat_v2_conv/Reshape_3:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_0/node_set_update/gat_v2_conv/Reshape_2:0\", shape=(None, 1, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_0/node_set_update/gat_v2_conv/Cast:0\", shape=(3,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/heng/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_0/node_set_update/gat_v2_conv/Reshape_6:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_0/node_set_update/gat_v2_conv/Reshape_5:0\", shape=(None, 1, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_7/gat_mpnn/message_passing_0/node_set_update/gat_v2_conv/Cast_1:0\", shape=(3,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 7s 58ms/step - loss: 0.5513 - sparse_categorical_accuracy: 0.7359 - sparse_categorical_crossentropy: 0.5513 - AUROC: 0.6318 - val_loss: 0.5147 - val_sparse_categorical_accuracy: 0.7305 - val_sparse_categorical_crossentropy: 0.5147 - val_AUROC: 0.7290\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 2s 40ms/step - loss: 0.4745 - sparse_categorical_accuracy: 0.7588 - sparse_categorical_crossentropy: 0.4745 - AUROC: 0.7798 - val_loss: 0.4755 - val_sparse_categorical_accuracy: 0.7565 - val_sparse_categorical_crossentropy: 0.4755 - val_AUROC: 0.7876\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 2s 40ms/step - loss: 0.4467 - sparse_categorical_accuracy: 0.7841 - sparse_categorical_crossentropy: 0.4467 - AUROC: 0.8148 - val_loss: 0.4552 - val_sparse_categorical_accuracy: 0.7786 - val_sparse_categorical_crossentropy: 0.4552 - val_AUROC: 0.8117\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 2s 40ms/step - loss: 0.4255 - sparse_categorical_accuracy: 0.8017 - sparse_categorical_crossentropy: 0.4255 - AUROC: 0.8365 - val_loss: 0.4323 - val_sparse_categorical_accuracy: 0.8014 - val_sparse_categorical_crossentropy: 0.4323 - val_AUROC: 0.8346\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 2s 40ms/step - loss: 0.4094 - sparse_categorical_accuracy: 0.8136 - sparse_categorical_crossentropy: 0.4094 - AUROC: 0.8506 - val_loss: 0.4166 - val_sparse_categorical_accuracy: 0.8125 - val_sparse_categorical_crossentropy: 0.4166 - val_AUROC: 0.8463\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.3985 - sparse_categorical_accuracy: 0.8216 - sparse_categorical_crossentropy: 0.3985 - AUROC: 0.8590 - val_loss: 0.4251 - val_sparse_categorical_accuracy: 0.8151 - val_sparse_categorical_crossentropy: 0.4251 - val_AUROC: 0.8449\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.3926 - sparse_categorical_accuracy: 0.8263 - sparse_categorical_crossentropy: 0.3926 - AUROC: 0.8636 - val_loss: 0.4203 - val_sparse_categorical_accuracy: 0.8112 - val_sparse_categorical_crossentropy: 0.4203 - val_AUROC: 0.8445\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 2s 40ms/step - loss: 0.3839 - sparse_categorical_accuracy: 0.8292 - sparse_categorical_crossentropy: 0.3839 - AUROC: 0.8703 - val_loss: 0.4048 - val_sparse_categorical_accuracy: 0.8138 - val_sparse_categorical_crossentropy: 0.4048 - val_AUROC: 0.8564\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 2s 40ms/step - loss: 0.3759 - sparse_categorical_accuracy: 0.8364 - sparse_categorical_crossentropy: 0.3759 - AUROC: 0.8757 - val_loss: 0.4040 - val_sparse_categorical_accuracy: 0.8197 - val_sparse_categorical_crossentropy: 0.4040 - val_AUROC: 0.8584\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.3669 - sparse_categorical_accuracy: 0.8409 - sparse_categorical_crossentropy: 0.3669 - AUROC: 0.8819 - val_loss: 0.4065 - val_sparse_categorical_accuracy: 0.8216 - val_sparse_categorical_crossentropy: 0.4065 - val_AUROC: 0.8546\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.3642 - sparse_categorical_accuracy: 0.8409 - sparse_categorical_crossentropy: 0.3642 - AUROC: 0.8836 - val_loss: 0.4116 - val_sparse_categorical_accuracy: 0.8242 - val_sparse_categorical_crossentropy: 0.4116 - val_AUROC: 0.8613\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.3576 - sparse_categorical_accuracy: 0.8478 - sparse_categorical_crossentropy: 0.3576 - AUROC: 0.8883 - val_loss: 0.4042 - val_sparse_categorical_accuracy: 0.8262 - val_sparse_categorical_crossentropy: 0.4042 - val_AUROC: 0.8590\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 0.3629 - sparse_categorical_accuracy: 0.8441 - sparse_categorical_crossentropy: 0.3629 - AUROC: 0.8845 - val_loss: 0.3924 - val_sparse_categorical_accuracy: 0.8333 - val_sparse_categorical_crossentropy: 0.3924 - val_AUROC: 0.8676\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.3527 - sparse_categorical_accuracy: 0.8500 - sparse_categorical_crossentropy: 0.3527 - AUROC: 0.8919 - val_loss: 0.3956 - val_sparse_categorical_accuracy: 0.8223 - val_sparse_categorical_crossentropy: 0.3956 - val_AUROC: 0.8656\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 2s 40ms/step - loss: 0.3544 - sparse_categorical_accuracy: 0.8495 - sparse_categorical_crossentropy: 0.3544 - AUROC: 0.8907 - val_loss: 0.3916 - val_sparse_categorical_accuracy: 0.8190 - val_sparse_categorical_crossentropy: 0.3916 - val_AUROC: 0.8704\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 0.3507 - sparse_categorical_accuracy: 0.8511 - sparse_categorical_crossentropy: 0.3507 - AUROC: 0.8931 - val_loss: 0.3912 - val_sparse_categorical_accuracy: 0.8249 - val_sparse_categorical_crossentropy: 0.3912 - val_AUROC: 0.8699\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.3424 - sparse_categorical_accuracy: 0.8589 - sparse_categorical_crossentropy: 0.3424 - AUROC: 0.8975 - val_loss: 0.3917 - val_sparse_categorical_accuracy: 0.8268 - val_sparse_categorical_crossentropy: 0.3917 - val_AUROC: 0.8696\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.3449 - sparse_categorical_accuracy: 0.8580 - sparse_categorical_crossentropy: 0.3449 - AUROC: 0.8957 - val_loss: 0.3939 - val_sparse_categorical_accuracy: 0.8255 - val_sparse_categorical_crossentropy: 0.3939 - val_AUROC: 0.8693\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 2s 40ms/step - loss: 0.3397 - sparse_categorical_accuracy: 0.8570 - sparse_categorical_crossentropy: 0.3397 - AUROC: 0.8991 - val_loss: 0.3892 - val_sparse_categorical_accuracy: 0.8327 - val_sparse_categorical_crossentropy: 0.3892 - val_AUROC: 0.8728\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 2s 40ms/step - loss: 0.3374 - sparse_categorical_accuracy: 0.8597 - sparse_categorical_crossentropy: 0.3374 - AUROC: 0.9005 - val_loss: 0.3947 - val_sparse_categorical_accuracy: 0.8307 - val_sparse_categorical_crossentropy: 0.3947 - val_AUROC: 0.8712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-29 22:06:18.770933: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as message_passing_0_layer_call_fn, message_passing_0_layer_call_and_return_conditional_losses, message_passing_1_layer_call_fn, message_passing_1_layer_call_and_return_conditional_losses, message_passing_2_layer_call_fn while saving (showing 5 of 128). These functions will not be directly callable after loading.\n",
      "/home/heng/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tensorflow_gnn.GraphTensorSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "/home/heng/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tensorflow_gnn.ContextSpec.v2; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "/home/heng/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tensorflow_gnn.NodeSetSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "/home/heng/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tensorflow_gnn.EdgeSetSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "/home/heng/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tensorflow_gnn.AdjacencySpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n"
     ]
    }
   ],
   "source": [
    "runner.run(\n",
    "    train_ds_provider=train_dataset_provider,\n",
    "    valid_ds_provider=valid_dataset_provider,\n",
    "    feature_processors=[extract_labels],\n",
    "    model_fn=get_model_creation_fn(hidden_size=128, hops=8),\n",
    "    task=task,\n",
    "    trainer=trainer,\n",
    "    epochs=20,\n",
    "    optimizer_fn=tf.keras.optimizers.Adam,\n",
    "    gtspec=graph_spec,\n",
    "    global_batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3ed456",
   "metadata": {},
   "source": [
    "## 指标可视化\n",
    "\n",
    "可视化训练和验证期间收集的各种指标的一种直接方法是使用 TensorBoard。理想情况下，以下魔法应该起作用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8e4d9b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill 401550"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "81874372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-819a72ba6f86c4cf\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-819a72ba6f86c4cf\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir model --bind_all\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a10895",
   "metadata": {},
   "source": [
    "<img src=\"gnn2.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b38bd5",
   "metadata": {},
   "source": [
    "准确率达到87%左右\n",
    "<img src=\"gnn3.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121f8fda",
   "metadata": {},
   "source": [
    "损失逐渐减少，直到我们开始过度拟合（橙色线是训练，蓝色线是验证）：\n",
    "<img src=\"gnn4.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efa758c",
   "metadata": {},
   "source": [
    "## 结论\n",
    "\n",
    "在本笔记本中，我们了解了如何使用 TF-GNN 以端到端的方式训练用于图二元分类的 GNN 模型。 运行协调器的最后一个单元汇集了我们在此过程中引入的所有元素，即：\n",
    "\n",
    "1. 构造的 DatasetProvider 兼容对象 train_dataset_provider 和 valid_dataset_provider 用于提供数据\n",
    "1. 内置的模型构造函数 get_model_creation_fn 与 组件一起组装 GNN\n",
    "1. 定义的 GraphBinaryClassification 任务指定读出和预测头，以及损失和指标。\n",
    "1. 创建的 KerasTrainer 和目标特征提取器用于监督训练  \n",
    "\n",
    "虽然从这样一个小例子中可能不会立即明显看出，但 TF-GNN 在每个步骤中都提供了帮助，不仅提供了我们需要在图上执行的底层操作，而且还提供了许多有用的协议和辅助函数来处理大部分样板代码 否则我们会有要求。 将它们与协调器一起使用意味着所有组件都可以轻松扩展和/或替换。 此外，它至少在原则上允许我们轻松地独立缩放各个移动部件，而不会产生不必要的痛苦。 例如，在训练器中引入一个重要的策略，我们可以将训练分布在多个 GPU 上，或者最终分布在 TPU 上，同时还可以通过传递到 DatasetProvider 的 InputContext 并行化我们的输入管道。\n",
    "\n",
    "我们获得的药物心脏毒性数据集的结果很好，但并不令人印象深刻。 考虑到我们实现的非常简单的基于 GAT 的模型以及我们没有进行超参数优化或有原则的架构选择这一事实，这是可以预料到的。 为了进行比较，其中我们看到我们的AUROC结果与那里考虑的GNN基线基本一致：\n",
    "\n",
    "<img src=\"gnn5.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44e1daf",
   "metadata": {},
   "source": [
    "## 参考\n",
    "1. [Introduction to TF-GNN](https://www.kaggle.com/code/fidels/introduction-to-tf-gnn/notebook)\n",
    "2. [Graph Neural Networks: Graph Classification](https://blog.dataiku.com/graph-neural-networks-part-three)\n",
    "3. [A Gentle Introduction to Graph Neural Networks](https://distill.pub/2021/gnn-intro/)\n",
    "4. [Graph Representation Learning Book](https://www.cs.mcgill.ca/~wlh/grl_book/)\n",
    "5. [TensorFlow GNN guide](https://github.com/tensorflow/gnn/blob/main/tensorflow_gnn/docs/guide/intro.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478fa2ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
